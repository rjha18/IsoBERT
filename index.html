<!doctype html>
<html class="no-js" lang="">

<head>
  <meta charset="utf-8">
  <title>IsoBERT</title>

  <link rel="stylesheet" href="css/bootstrap.min.css">
</head>

<body>
  <section class="py-5 container">
    <div class="row py-lg-5">
      <div class="col-lg-10 col-md-8 mx-auto text-center">
        <h1 class="fw-light">Nonlinear Dimensionality Reduction on BERT</h1>
      </div>
      <div class="py-3 col-lg-10 col-md-0 mx-auto">
        <h3 class="fw-light">Abstract</h3>
        <p class="lead text-muted">Something short and leading about the collection below—its contents, the creator, etc. Make it short and sweet, but not too short so folks don’t simply skip over it entirely.</p>
        <p class="text-muted">Something short and leading about the collection below—its contents, the creator, etc. Make it short and sweet, but not too short so folks don’t simply skip over it entirely.</p>
      </div>

      <div class="py-3 col-lg-10 col-md-0 mx-auto">
        <h3 class="fw-light">Problem Statement</h3>
        <p class="lead text-muted">State of the art sentence embedding models consist of networks with many layers and millions of parameters, ultimately outputting a vector with hundreds or thousands of features. This leads to a long and expensive process of computing sentence level embeddings and storing large feature vectors. Some sentence embeddings models have looked to solve this problem by reducing the number of layers and parameters in the model to preserve as much information as possible while reducing the computational effort and storage required to produce embeddings. DistilBERT offers comparable performance to other sentence embedding models, outputting the same 768 features, while only using half the number of layers and parameters as the standard BERT model (https://arxiv.org/pdf/1910.01108.pdf). Other state of the art models like ALBERT (https://arxiv.org/abs/1909.11942) seek to solve this problem in a similar way, while also reducing the dimensionality of the sentence embeddings. While there is a lot of work being done optimizing the models themselves, another approach is reducing the dimensionality of the output embeddings. For many problems, 768 dimension features can be reduced to much smaller feature vectors to accomplish the same goal. Further, we hypothesize that different texts, or different classes of text have different embedded shapes which can be used to reduce the dimensionality of sentence embeddings for text classification and sentiment analysis.</p>
      </div>

      <div class="py-3 col-lg-10 col-md-0 mx-auto">
        <h3 class="fw-light">Related Work</h3>
        <p class="lead text-muted">Something short and leading about the collection below—its contents, the creator, etc. Make it short and sweet, but not too short so folks don’t simply skip over it entirely.</p>
      </div>

      <div class="py-3 col-lg-10 col-md-0 mx-auto">
        <h3 class="fw-light">Methadology</h3>
        <p class="lead text-muted">Something short and leading about the collection below—its contents, the creator, etc. Make it short and sweet, but not too short so folks don’t simply skip over it entirely.</p>
      </div>

      <div class="py-3 col-lg-10 col-md-0 mx-auto">
        <h3 class="fw-light">Experiments/Evaluation</h3>
        <p class="lead text-muted">Something short and leading about the collection below—its contents, the creator, etc. Make it short and sweet, but not too short so folks don’t simply skip over it entirely.</p>
      </div>

      <div class="py-3 col-lg-10 col-md-0 mx-auto">
        <h3 class="fw-light">Results</h3>
        <p class="lead text-muted">Something short and leading about the collection below—its contents, the creator, etc. Make it short and sweet, but not too short so folks don’t simply skip over it entirely.</p>
      </div>

      <div class="py-3 col-lg-10 col-md-0 mx-auto">
        <h3 class="fw-light">Examples</h3>
        <p class="lead text-muted">Something short and leading about the collection below—its contents, the creator, etc. Make it short and sweet, but not too short so folks don’t simply skip over it entirely.</p>
      </div>

      <div class="py-3 col-lg-10 col-md-0 mx-auto">
        <h3 class="fw-light">Video</h3>
        <p class="lead text-muted">Something short and leading about the collection below—its contents, the creator, etc. Make it short and sweet, but not too short so folks don’t simply skip over it entirely.</p>
      </div>
    </div>
  </section>
  <section class="text-left container">
    <div class="row py-lg-5">
      
    </div>
  </section>
</body>

</html>

